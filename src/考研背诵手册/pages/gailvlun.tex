\chapter{概率论}

\newcommand{\bbP}{\mathbb{P}}

\section{随机事件和概率}

\subsection{大纲要求}

1. 了解样本空间（基本事件空间）的概念，理解随机事件的概念，掌握事件的关系及运算。

2. 理解概率、条件概率的概念，掌握概率的基本性质，会计算古典型概率和几何型概率，掌握概率的加法公式、减法公式、乘法公式、全概率公式以及贝叶斯（Bayes）公式。

3. 理解事件独立性的概念，掌握用事件独立性进行概率计算；理解独立重复试验的概念，掌握计算有关事件概率的方法。


\section{随机变量及其分布}

\subsection{大纲要求}

1. 理解随机变量的概念，理解分布函数
$$
	F(x) = P\{X \leqslant x\}(-\infty < x < +\infty)
$$
的概念及性质，会计算与随机变量相联系的事件的概率。

2. 理解离散型随机变量及其概率分布的概念，掌握 $0-1$ 分布、二项分布 $B(n, p)$、几何分布、超几何分布、泊松（Poisson）分布 $P(\lambda)$ 及其应用。

3. 了解泊松定理的结论和应用条件，会用泊松分布近似表示二项分布。

4. 理解连续型随机变量及其概率密度的概念，掌握均匀分布 $U(a, b)$、 正态分布 $N(\mu, \sigma^2)$、指数分布及其应用，其中参数为 $\lambda(\lambda > 0)$ 的指数分布 $E(\lambda)$ 的概率密度为
$$
	f(x) = \begin{cases} \lambda e^{-\lambda x}, & x > 0 \\ 0, &x \leqslant 0 \end{cases}
$$
5. 会求随机变量函数的分布。

\subsection{常见分布}

\paragraph{二项分布 $X \sim B(n, p)$}
如果 $X$ 的概率分布为
\[ \bbP\{X = k\} = \binom{n}{k} p^k(1 - p)^{n-k}. \quad k = 0, 1, \cdots, n \]
特别的，当 $n=1$ 时称为二项分布。二项分布也是 $n$ 重伯努利实验中事件 $A$ 发生的次数，其中 $\bbP(A) = p$。

\paragraph{泊松分布 $X \sim P(\lambda)$}
如果 $X$ 的概率分布为
\[ \bbP\{X = k\} = \frac{\lambda^k}{k!} \ee^{-\lambda} , \quad k = 0, 1, \cdots \]


\paragraph{几何分布 $X \sim G(p)$}
如果 $X$ 的概率分布为
\[ \bbP\{X=k\} = (1 - p)^{k-1}p, \quad k = 1, 2, \cdots \]

\paragraph{超几何分布 $X \sim H(n, N, M)$}
如果 $X$ 的概率分布为
\[ \bbP\{X = k\} = \frac{\binom{M}{k} \binom{N - M}{n - k}}{\binom{N}{n}}, \quad \max(0, n - N + M) \leqslant k \leqslant \min(M, n) \]
设有 $N$ 个产品组成的整体，其中有 $M$ 个不合格产品，从中取出 $n$ 个，次品数为 $k$，这就是组合意义。

\paragraph{均匀分布 $X \sim U(a, b)$}
如果 $X$ 的概率密度函数为
\[ f(x) = \frac{1}{b - a}, \quad a < x < b \]

\paragraph{指数分布 $X \sim E(\lambda)$}
如果 $X$ 的概率密度函数为
\[ f(x) = \lambda \ee^{-\lambda x}, \quad x > 0 \]

\paragraph{正态分布 $X \sim N(\mu, \sigma^2)$}
如果 $X$ 的概率密度为
\[ f(x) = \frac{1}{\sqrt{2 \pi}  \sigma} \exp \left(- \frac{(x - \mu)^2}{2\sigma^2}  \right) \]
如果 $X \sim N(\mu, \sigma^2)$，则 $\frac{X - \mu}{\sigma} \sim N(0, 1)$。


\section{多维随机变量及其分布}

\subsection{大纲要求}

1. 理解多维随机变量的概念，理解多维随机变量的分布的概念和性质，理解二维离散型随机变量的概率分布、边缘分布和条件分布，理解二维连续型随机变量的概率密度、边缘密度和条件密度，会求与二维随机变量相关事件的概率。

2. 理解随机变量的独立性及不相关性的概念，掌握随机变量相互独立的条件。

3. 掌握二维均匀分布，了解二维正态分布 $N(\mu_1, \mu_2; \sigma_1^2, \sigma_2^2; \rho)$ 的概率密度，理解其中参数的概率意义。

4. 会求两个随机变量简单函数的分布，会求多个相互独立随机变量简单函数的分布。

\subsection{两个随机变量简单函数}

对于随机变量 $(X, Y)$，求 $g(X, Y)$ 的概率密度和分布函数有两种方法：

\subsubsection*{定义法}

设其概率密度函数为 $f(x, y)$，先求 $Z = g(X, Y)$ 的概率密度
\[ F_Z(z) = \bbP\{Z \leqslant z\} = \bbP\{g(X,Y) \leqslant z\} = \iint_{g(X,Y) \leqslant z} f(x, y) \d x \d y \]
其概率密度则为 $f_Z(z) = \frac{\d F_z(z)}{\d z}$。

\subsubsection*{公式法}

对于 $Z = X + Y$，则
\[ f_Z(z) = \int_{-\infty}^{+\infty} f(z - y, y) \d y = \int_{-\infty}^{+\infty} f(x, z - x) \d x \]
对于 $Z = XY$，则
\[ f_Z(z) = \int_{-\infty}^{+\infty} \frac{1}{|x|}f\left(x, \frac{z}{x}\right) \d y = \int_{-\infty}^{+\infty} \frac{1}{|y|}f\left(\frac{z}{y}, y\right) \d x \]
对于 $Z = \frac{X}{Y}$，则
\[ f_Z(z) = \int_{-\infty}^{+\infty} |y|f(yz, y) \d y \]
对于 $Z = \max\{X, Y\}$，则
\[ F_Z(z) = F_X(z)F_Y(z) \]
对于 $Z = \min\{X, Y\}$，则
\[ F_Z(z) = 1 - (1 - F_X(z))(1 - F_Y(z)) \]

\section{随机变量的数字特征}

\subsection{大纲要求}

1. 理解随机变量数字特征（数学期望、方差、标准差、矩、协方差、相关系数）的概念，会运用数字特征的基本性质，并掌握常用分布的数字特征。

2. 会求随机变量函数的数学期望。

\subsection{期望和方差}

\subsection*{期望}

设 $X$ 是随机变量，其分布列为 $p_i = \bbP\{X = x_i\}$，记
\[ E[X] = \sum_{i=1}^\infty x_i p_i, \quad E[g(X)] = \sum_{i=1}^\infty g(x_i) p_i \]
为随机变量 $X$ 的数学期望。若 $X$ 是连续型随机变量，则记
\[ E[X] = \int_{-\infty}^{+\infty} x f(x) \d x, \quad E[g(X)] = \int_{-\infty}^{+\infty} g(x) f(x) \d x \]
为其期望

期望的性质
\begin{itemize}
	\item 对于常数 $C$，有 $E[C] = C$；
	\item 线性性：$E[\sum k_iX_i] = \sum k_i E[X]$；
	\item 独立性：如果 $X_1, \cdots, X_n$ 相互独立，$E[X_1X_2\cdots X_n] = E[X_1] \cdots E[X_n]$。
\end{itemize}

\subsection*{方差}

我们记 $E[(X - EX)^2]$ 为 $X$ 的方差，有
\[ D(X) = E[(X - EX)^2] = E(X^2) - (EX)^2 \]
称 $\sqrt{D(X)}$ 为 $X$ 的标准差，或者均方差，记为 $\sigma(X)$。

若 $X$ 是离散型随机变量，则
\[ D(X) = \sum_{i=1}^{\infty} (x_i - E)^2 p_i \]
连续性随机变量，则
\[ D(X) = \int_{-\infty}^{\infty} (x-E)^2 f(x) \d x \]

方差的性质
\begin{itemize}
	\item 对于常数 $C$，有 $D[C] = C^2$；
	\item 线性性：如果 $X_1, \cdots, X_n$ 相互独立，$D[\sum k_iX_i] = \sum k_i^2 E[X]$。
\end{itemize}

\subsection{协方差和相关系数}

\subsection*{矩}
\begin{itemize}
	\item $k$ 阶原点矩：$E[X^k]$；
	\item $k$ 阶中心距：$E[(X - EX)^k]$；
	\item $k + l$ 阶混合矩：$E[X^k Y^l]$；
	\item $k + l$ 阶中心距：$E[(X - EX)^k (Y - EY)^l]$；
\end{itemize}

\subsection*{协方差}

\newcommand{\opCov}{\operatorname{Cov}}

我们定义 $(X, Y)$ 的协方差为
\[ \opCov(X, Y) = E[(X - EX)(Y - EY))] = E(XY) - EX \cdot EY \]

称 $\rho_{XY} = \frac{\opCov(X, Y)}{\sqrt{D(X) D(Y)}}$ 为 $X, Y$ 的相关系数。

\begin{theorem}[切比雪夫不等式]
	如果随机变量 $X$ 的期望 $E(X)$ 和方差 $D(X)$ 存在，则对任意 $\eps > 0$ 有
	\[ \bbP\{|X - E(X)| < \eps\} \geqslant 1 - \frac{D(X)}{\eps^2} \]
\end{theorem}



\subsection*{协方差的性质}

\begin{itemize}
	\item $\opCov(X, Y) = \opCov(Y, X)$；
	\item $\opCov(X, X) = DX$；
	\item $\opCov(aX, bY) = ab \opCov(X, Y)$；
	\item $\opCov(X_1 + X_2, Y) = \opCov(X_1, Y) + \opCov(X_2, Y)$；
	\item $D(X \pm Y) = DX + DY \pm 2Cov(X, Y)$；
\end{itemize}

$X, Y$ 相互独立可以推出不相关，但反之不行；

$X, Y$ 不相关与下列命题互推
\begin{itemize}
	\item $\rho_{XY} = 0$；
	\item $\opCov(X, Y) = 0$
	\item $E[XY] = EX \cdot EY$；
	\item $D(X \pm Y) = DX + DY$。
\end{itemize}

\subsection{\texorpdfstring{$\Gamma$ 函数}{Γ 函数}}

$\Gamma$ 函数是一有力的工具，其定义为
\[ \Gamma(z) = \int_{0}^{+\infty} t^{z-1} \ee^{-t} \d t \]
其具有递推式和余元公式
\[ \Gamma(z + 1) = z \Gamma(z), \quad \Gamma(z) \Gamma(1-z) = \frac{\pi}{\sin \pi z} \]
特殊的，$\Gamma(n + 1) = n!$，和 $\Gamma(\frac{1}{2}) = \sqrt{\pi}$。不难化简
\[ I_n = \int_{0}^{+\infty} x^n \ee^{-x^2} \d x = \frac{1}{2} \int_{0}^{+\infty} \left(x^2\right)^{\frac{n+1}{2}} \ee^{-x^2} \d \left(x^2\right) = \frac{1}{2} \Gamma\left(\frac{n+1}{2}\right)  \]

\section{大数定律和中心极限定理}

\subsection{大纲要求}

1. 了解切比雪夫不等式。

2. 了解切比雪夫大数定律、伯努利大数定律和辛钦大数定律（独立同分布随机变量序列的大数定律）。

3. 了解棣莫弗-拉普拉斯定理（二项分布以正态分布为极限分布）和列维-林德伯格定理（独立同分布随机变量序列的中心极限定理）。

\subsection{神秘公式}

设随机变量 $X$ 与随机变量序列 $\{X_n\}$，如果对任意的 $\eps > 0$ 有
\[ \lim_{n \to \infty} \bbP\{|X_n - X| < \eps \} =1 \]
则称随机变量序列 $\{X_n\}$ 依概率收敛于随机变量 $X$，记为
\[ \lim_{n \to \infty} X_n = X(P), \quad \text{或}\ X_n \stackrel{P}{\longrightarrow} X(n \to \infty) \]

\begin{theorem}[切比雪夫大数定律]
	设 $\{X_n\}$ 是相互独立的随机变量序列，如果方差 $D(X)$ 存在且有一致有上界，则 $\{X_n\}$ 服从大数定律
	\[ \frac{1}{n} \sum_{i=1}^n X_i \stackrel{P}{\longrightarrow} \frac{1}{n} \sum_{i=1}^n E(X_i) \]
\end{theorem}

\begin{theorem}[伯努利大数定律]
	假设 $\mu_n$ 是 $n$ 重伯努利实验中时间 $A$ 发生的次数，在每次实验中 $A$ 发生的概率为 $p(0 < p < 1)$，则
	\[ \frac{\mu_n}{n} \stackrel{P}{\longrightarrow} p \]
\end{theorem}

\begin{theorem}[辛钦大数定律]
	设 $\{X_n\}$ 是独立同分布的随机变量序列，如果 $E(X_i) = \mu$ 存在，则
	\[ \frac{1}{n} \sum_{i=1}^n X_i \stackrel{P}{\longrightarrow} \mu \]
\end{theorem}

\begin{theorem}[列维 - 林德伯格定理]
	假设 $\{X_n\}$ 是独立同分布的随机变量序列，如果
	\[ E(X_i) = \mu, D(X_i) = \sigma^2 > 0 \]
	存在，则对任意的实数 $x$ 有
	\[ \lim_{n \to \infty} \bbP\left\{ \frac{\sum_{i=1}^n X_i - n \mu}{\sigma \sqrt{n}} \leqslant x \right\} = \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^x \exp\left(-\frac{t^2}{2}\right) \d t = \Phi(x)  \]
\end{theorem}

\begin{theorem}[棣莫弗 - 拉普拉斯定理]
	设随机变量 $Y_n \sim B(n, p)$，其中 $0 < p < 1$ 且 $n > 1$，则对任意的实数 $x$，有
	\[ \lim_{n \to \infty} \bbP\left\{ \frac{Y_n - np}{\sqrt{np(1 - p)}} \leqslant x \right\} = \frac{1}{\sqrt{2 \pi}} \int_{-\infty}^x \exp\left(-\frac{t^2}{2}\right) \d t = \Phi(x)  \]
\end{theorem}


\section{数理统计的基本概念}

\subsection{大纲要求}

1. 理解总体、简单随机样本、统计量、样本均值、样本方差及样本矩的概念，其中样本
方差定义为
\[ S^2 = \frac{1}{n-1} \sum_{t=1}^n (\chi_1 = \chi) \cal \]
2. 了解 $\chi^2$ 分布、$t$ 分布、$F$ 分布的概念及性质，了解上侧 $\alpha$ 分位数的概念并会查表计算。

3. 了解正态总体的常用抽样分布。

\subsection{统计量}

研究对象的全体称为总体，组成总体的每一个元素称为个体。我们把总体和 $X$ 等同起来，所谓总体的分布就是指 $X$ 的分布。

$n$ 个相互独立且与总体 $X$ 具有相同概率分布的随机变量 $\seq{x}{n}$ 所组成的总体为 $(\seq{x}{n})$ 称为来自总体 $X$ 容量为 $n$ 的一个简单随机样本，简称样本。一次抽样结果的 $n$ 个具体数值称为 $\seq{x}{n}$ 的一个观测值（样本值）。

假设总体 $X$ 的分布函数为 $F$，则 $(\seq{x}{n})$ 的分布函数为
\[ F(\seq{x}{n}) = \prod_{i=1}^n F(x_i) \]

设 $\seq{x}{n}$ 为来自总体 $X$ 的一个样本，$g$ 为仅与 $x$ 有关的 $n$ 元函数，则称 $g$ 为样本的一个统计量。若 $(\seq{x}{n})$ 为样本值，则 $g(\seq{x}{n})$ 为观测值。

样本均值
\[ \overline{X} = \frac{1}{n} \sum_{i=1}^n X_i \]
样本方差
\[ S^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \overline{X})^2 \]
样本 $k$ 阶（原点）矩
\[ A_k = \frac{1}{n} \sum_{i=1}^n X_i^k \]
样本 $k$ 阶中心矩
\[ B_k = \frac{1}{n} \sum_{i=1}^n (X_i - \overline{X})^k \]

将 $n$ 个观测量从小到大的顺序排列，记随机变量 $X_{(k)}$ 为第 $k$ 顺序统计量。

常用统计量：

\[
	\begin{aligned}
		E(X_i)          & = E(X)             \\
		D(X_i)          & = D(X)             \\
		E(\overline{X}) & = E(X)             \\
		D(\overline{X}) & = \frac{1}{n} D(X) \\
		E(S^2)          & = D(X)
	\end{aligned}
\]

\subsection{三大分布}

\paragraph{$\chi^2$ 分布}

若随机变量 $\seq{x}{n}$ 相互独立且都服从标准正态分布，则随机变量 $X = \sum X_i^2$ 服从自由度为 $n$ 的 $\chi^2$ 分布，记为 $X \sim \chi^2(n)$。

对于给定的 $\alpha(0 < \alpha < 1)$，称满足
\[ \bbP\left\{\chi^2 > \chi_\alpha^2(n)\right\} = \int_{\chi_\alpha^2(n)}^n f(x) \d x = \alpha  \]
的 $\chi_\alpha^2(n)$ 为 $\chi^2(n)$ 分布的上 $\alpha$ 分位点。

\paragraph{$t$ 分布}

设随机变量 $X \sim N(0, 1), Y \sim \chi^2(n)$，$X$ 与 $Y$ 互相独立，则随机变量 $t = \frac{X}{\sqrt{Y / n}}$ 服从自由度为 $n$ 的 $t$ 分布，记为 $t \sim t(n)$.

\paragraph{$F$ 分布}

设随机变量 $X \sim \chi^2(n_1), y \sim \chi^2(n_2)$，且 $X$ 与 $Y$ 相互独立，则 $F = \frac{X / n_1}{Y / n_2}$ 服从自由度为 $(n_1, n_2)$ 的 $F$ 分布，记为 $F \sim F(n_1, n_2)$。


\section{参数估计}

\subsection{大纲要求}

1. 理解参数的点估计、估计量与估计值的概念。

2. 掌握矩估计法（一阶矩、二阶矩）和最大似然估计法。

3. 了解估计量的无偏性、有效性（最小方差性）和一致性（相合性）的概念，并会验证估计量的无偏性。

4. 理解区间估计的概念，会求单个正态总体的均值和方差的置信区间，会求两个正态总
体的均值差和方差比的置信区间。

\subsection{神秘估计}

设总体 $X$ 的分布函数为 $F(x; \theta)$，其中 $\theta$ 是一个未知参数，$\seq{x}{n}$ 是取自总体 $X$ 的一个样本。由样本构造一个适当的统计量 $\hat{\theta}(\seq{x}{n})$ 作为参数 $\theta$ 的估计，则称 $\hat{\theta}$ 为其估计量。

如果 $\seq{x}{n}$ 是样本的一个观察值，将其带入估计量得值 $\hat{\theta}(\seq{x}{n})$ 并以此值作为未知参数的近似值，则称为 $\theta$ 的估计值。

\paragraph{矩估计法}

设总体 $X$ 分布有 $n$ 个样本，有 $k$ 个未知参数。若 $X$ 的原点矩存在，我们令样本矩等于总体矩
\[ \frac{1}{n} \sum_{i=1}^{N} X_i^l = E(X^l), \quad l = 1, \cdots, k \]
这是包含 $k$ 个参数的 $k$ 个方程，由此解得矩估计量和矩估计值。

一般约定：用矩法方程求总体未知参数的估计量时，从低阶开始。

\paragraph{最大似然估计法}

似然性与概率的区别：
\begin{itemize}
	\item 概率 $p(x;\theta)$ 是在已知参数 $\theta$ 的情况下，发生观测结果 $x$ 的概率；
	\item 似然性 $L(x; \theta)$ 是从观测结果 $x$ 出发，分布函数为 $\theta$ 的可能性大小。
\end{itemize}

最大似然原理：对未知参数 $\theta$ 进行估计时，在该参数可能的取值范围 $I$ 内选取，用使样本获得观测值 $\seq{x}{n}$ 的概率最大的参数值 $\hat{\theta}$ 作为 $\theta$ 的估计。

假设 $X$ 是离散型随机变量，其概率分布为 $\bbP\{X = x\} = p(x; \theta)$，那么求其取值概率
\[ L(\seq{x}{n};\theta) = \bbP\{X_1 = x_1, \cdots, X_n = x_n\} = \prod_{i=1}^n \bbP\{X_i=x_i\} = \prod_{i=1}^n p(x_i; \theta) \]
称为样本的似然函数。若存在 $\hat{\theta}$ 使得 $L$ 取到最大值，则称 $\hat{\theta}$ 为最大似然估计值，对应的统计量是 $\theta$ 的最大似然估计量。

同理，连续型随机变量也有
\[ L(\seq{x}{n}; \theta) = \prod_{i=1}^n f(x_i; \theta) \]

最大似然估计法步骤：
\begin{enumerate}
	\item 计算似然函数 $L(\theta)$
	\item 求关于 $\theta$ 的最大值点，一般情况下可微，求导或者对数求导
	      \[ \frac{\d L}{\d \theta} = 0, \quad \frac{\d (\ln L)}{\d \theta} = \frac{L'(\theta)}{L(\theta)} = 0 \]
	      得到极值点
	\item 用样本 $X_i$ 代替样本值 $x_i$，得到最大似然估计量 $\hat{\theta}$。
\end{enumerate}
倘若有多个参数 $\theta$，也是计算多元极值点。

\section{假设检验}

\subsection{大纲要求}

1. 理解显著性检验的基本思想，掌握假设检验的基本步骤，了解假设检验可能产生的两类错误。

2. 掌握单个及两个正态总体的均值和方差的假设检验
